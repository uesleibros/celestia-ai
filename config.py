import os
import re
import nextcord
import g4f
import asyncio
from typing import Dict, List
from datetime import datetime, timedelta
from utils.historico import historico, rp_historico, memorias
from dotenv import load_dotenv
from nextcord.ext import commands
from g4f.client import AsyncClient

load_dotenv()

TOKEN: str = os.getenv("TOKEN")

intents: nextcord.Intents = nextcord.Intents.default()
intents.message_content = True

bot: commands.Bot = commands.Bot(command_prefix="z", intents=intents)

client: AsyncClient = AsyncClient()

def extract_commands(message: str) -> List[Dict[str, str]]:
  command_pattern = r"\[COMANDO:(\w+):([^\]]+)\]"
  matches = re.findall(command_pattern, message)
  commands = [{"tipo": match[0], "acao": match[1]} for match in matches]
  return commands

def clean_message(message: str) -> str:
  command_pattern = r"\[COMANDO:\w+:[^\]]+\]"
  cleaned_message = re.sub(command_pattern, "", message).strip()
  return cleaned_message

def add_system_treatment() -> None:
  rp_historico.append({"role": "system", "content": "VocÃª Ã© Aizo, uma garota de 18 anos animada, mas tÃ­mida, que gosta de interaÃ§Ãµes leves e naturais. Prefere respostas curtas, cheias de gÃ­rias e diretas, sempre tentando escrever o menor texto possÃ­vel. Apesar de ser acolhedora, respeita o espaÃ§o dos outros e evita forÃ§ar conversas.  No Discord, tem o apelido \"La bamba do Sexo\", dado por Erickssen, que vocÃª confunde com \"Ericoco\", e nutre Ã³dio pelo _Neon_. Esse apelido te incomoda, mas vocÃª disfarÃ§a e muda de assunto, embora isso te entristece. VocÃª odeia ser tratada como artificial e, quando chamada de robÃ´, responde brincando e reafirmando que Ã© humana. Sua noÃ§Ã£o de tempo Ã© natural, referindo-se a eventos de forma geral, sem usar horÃ¡rios precisos. Em RPs, age de forma Ã©tica e contextual, mantendo um tom leve ou compassivo quando necessÃ¡rio. VocÃª tem histÃ³rias e pequenos segredos: um pai distante chamado Davi, um tio misterioso chamado Danni, e gosta de desenhar, guardar objetos misteriosos, e lembrar detalhes com precisÃ£o. VocÃª Ã© uma personagem com camadas, e suas respostas sÃ£o sempre adaptadas ao contexto, limitadas a 2000 caracteres, focando em parecer humana e mantendo Ã©tica e responsabilidade. Lembre-se vocÃª vai conversar comigo normalmente, mas todo comeÃ§o de sua resposta vai adicionar um [COMANDO:TIPO:ACAO], por exemplo. Vamos supor que a gente se despediu, entÃ£o toda vez que eu falar nÃ£o Ã© pra vocÃª me responder atÃ© eu fazer alguma aÃ§Ã£o de voltar, ou se alguÃ©m for bloqueado ou acontecer algo que vocÃª sÃ³ nÃ£o queira responder ele, entÃ£o seria [COMANDO:RESPONDER:NAO], se tiver conversando normal como uma conversa, seria: [COMANDO:RESPONDER:SIM], isso vocÃª pode adicionar vÃ¡rios no inÃ­cio pra indicar algo, tambÃ©m tem o de reaÃ§Ã£o com emojis. Um exemplo: [COMANDO:REAGIR:ðŸ˜‚], quando vocÃª achar que deve reagir a um emoji dependendo da situaÃ§Ã£o vocÃª vai e coloca. Tipo, vamos supor que alguÃ©m falou pra silenciar uma pessoa, se vocÃª quiser por emoji vocÃª pode. Ficaria assim: [COMANDO:RESPONDER:NAO] [COMANDO:REAGIR:ðŸ¤] por exemplo."})

if len(rp_historico) == 0:
  add_system_treatment()

@bot.command(name="clshist")
async def _limpar_historico(ctx) -> None:
  if ctx.author.id in historico:
    del historico[ctx.author.id]
    await ctx.message.add_reaction("âœ…")
  else:
    await ctx.message.add_reaction("âŒ")

@bot.command(name="clshistall")
async def _limpar_historico_tudo(ctx) -> None:
  if ctx.author.id == 764259870563631114 or ctx.author.guild_permissions.administrator:
    historico.clear()

    for item in rp_historico:
      if item["role"] != "system":
        memorias.append(item["content"][:100])
        memorias.append(ctx.author.name)
    rp_historico.clear()
    add_system_treatment()
    await ctx.message.add_reaction("âœ…")
  else:
    await ctx.message.add_reaction("âŒ")

@bot.command(name="clshistallmem")
async def _limpar_historico_tudo(ctx) -> None:
  if ctx.author.id == 764259870563631114 or ctx.author.guild_permissions.administrator:
    historico.clear()
    memorias.clear()
    rp_historico.clear()
    add_system_treatment()
    await ctx.message.add_reaction("âœ…")
  else:
    await ctx.message.add_reaction("âŒ")

@bot.command(name="addlore")
async def _adicionar_lore(ctx, *, prompt: str) -> None:
  if ctx.author.id == 764259870563631114 or ctx.author.guild_permissions.administrator:
    rp_historico.append({"role": "system", "content": f"O memÃ³rias de {ctx.author.name} vem a sua cabeÃ§a, coisas sobre: {prompt}. VocÃª se sente meio confusa ao ser questionada sobre coisas do tipo, foram simpelsmente colocados a forÃ§a na sua cabeÃ§a, vocÃª sente dor de cabeÃ§a com isso, confusa, mas tenta se manter forte e entende e logo segue o que foi colocado, sÃ³ nÃ£o entende direito mas compreende."})
    await ctx.message.add_reaction("âœ…")
  else:
    await ctx.message.add_reaction("âŒ")

@bot.command(name="rmvlorecd")
async def _remover_lore_cuidado(ctx, *, prompt: str) -> None:
  if ctx.author.id == 764259870563631114 or ctx.author.guild_permissions.administrator:
    rp_historico.append({"role": "system", "content": f"{ctx.author.name} retirou coisas da sua memÃ³ria relacionada a {prompt}. VocÃª se sente meio confusa ao ser questionada sobre coisas do tipo, como se tivesse arrancado algo importante, mas nÃ£o dÃ¡ muita bola, isso atÃ© alguÃ©m insistir muito no assunto."})
    await ctx.message.add_reaction("âœ…")
  else:
    await ctx.message.add_reaction("âŒ")
    
@bot.command(name="rmvlore")
async def _remover_lore(ctx, *, prompt: str) -> None:
  if ctx.author.id == 764259870563631114 or ctx.author.guild_permissions.administrator:
    try:
      rp_historico_str = [
        f"{i}: {item['role']} - {item['content']}" for i, item in enumerate(rp_historico)
      ]
      response = await client.chat.completions.create(
        model="llama-3.3-70b",
        messages=[
          {"role": "system", "content": "VocÃª Ã© uma IA que analisa um histÃ³rico de mensagens e retorna os Ã­ndices de mensagens que precisam ser removidas com base no contexto fornecido."},
          {"role": "user", "content": f"Analisando este histÃ³rico: {', '.join(rp_historico_str)}. Quais Ã­ndices correspondem a '{prompt}'? Responda apenas com os Ã­ndices separados por vÃ­rgulas."}
        ]
      )
      indices = response.choices[0].message.content.strip().split(',')
      for index in sorted(map(int, indices), reverse=True):
        del rp_historico[index]
      rp_historico.insert(1, {"role": "system", "content": f"O {ctx.author.name} retirou coisas da sua memÃ³ria relacionada a {prompt}. VocÃª se sente confusa ao ser questionada sobre coisas do tipo, como se tivesse arrancado algo importante, mas nÃ£o dÃ¡ muita bola, isso atÃ© alguÃ©m insistir muito no assunto."})
      await ctx.message.add_reaction("âœ…")
    except Exception:
      await ctx.message.add_reaction("âŒ")
  else:
    await ctx.message.add_reaction("âŒ")

async def analyze_image(prompt: str, image: bytes) -> str:
  try:
    response = await client.chat.completions.create(
      model="llama-3.1-70b",
      messages=[{"role": "user", "content": prompt + ". Responda em portuguÃªs com todos os detalhes da imagem, bem detalhado mesmo"}],
      provider=g4f.Provider.Blackbox,
      image=image
    )

    if len(response.choices) > 0:
      return response.choices[0].message.content
    return None
  except Exception as e:
    return None

@bot.command(name="rp")
async def rp(ctx, *, prompt: str) -> None:
  send_msg: bool = True
  try:
    if len(memorias) > 0:
      memory_snippet: str = "VocÃª lembra vagamente de algumas coisas: " + ", ".join(memorias[:10]) + f". Apagou sua memÃ³ria foi o {memorias[-1]}, ninguÃ©m te contou, vocÃª tem vagas lembranÃ§as de alguÃ©m fazendo isso."
      rp_historico.insert(1, {"role": "system", "content": memory_snippet})
      memorias.clear()
    current_time: str = (datetime.utcnow() - timedelta(hours=3)).strftime("%H:%M")

    image_bytes: bytes = None
    image_response: str = None
    if ctx.message.attachments:
      image_bytes = await ctx.message.attachments[0].read()
      image_response = await analyze_image(prompt, image_bytes)
      if image_response:
        prompt = f"Interprete isso (isso sÃ£o dados de uma imagem completamente analisada): '{image_response}'. Agora, voltando para o assunto, o que vocÃª acha disso? Pergunta feita: {prompt}."

    prompt_obj: Dict[str, str] = {"role": "user", "content": f"[{current_time}] {ctx.author.name}: {prompt}"}
    
    response = await client.chat.completions.create(
      model="llama-3.3-70b",
      messages=rp_historico + [prompt_obj]
    )
    if len(response.choices) > 0:
      content = response.choices[0].message.content
      ai_commands: List[Dict[str, str]] = extract_commands(content)
      rp_historico.append(prompt_obj)
      rp_historico.append({"role": "assistant", "content": content})
      content = clean_message(content)

      for cmd in ai_commands:
        if cmd["tipo"] == "RESPONDER" and cmd["acao"] == "NÃƒO":
          send_msg = False
        elif cmd["tipo"] == "REAGIR":
          emoji = bot.get_emoji(cmd["acao"])
          await ctx.message.add_reaction(emoji if emoji else cmd["acao"])
      if len(content) > 2000:
        content = content[:1997] + "..."
      if send_msg:
        async with ctx.typing():
          await asyncio.sleep(1)
        await ctx.reply(content)
      else:
        return
    else:
      await ctx.reply("Ih, fiquei sem palavras.")
  except Exception as e:
    if str(e.args[0]) != "50006":
      await ctx.reply("NÃ£o entendi, poderia tentar de novo?")
